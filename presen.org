#+title: Classical Planning in Deep Latent Space
#+author: Masataro Asai
#+include: "head.org"
#+LINK: img file:img/%s
#+LINK: png file:img/%s.png
#+LINK: jpg file:img/%s.jpg
#+LINK: spng file:img/static/%s.png
#+LINK: sjpg file:img/static/%s.jpg

#+BEGIN_outline-text-1
#+BEGIN_CENTER
æ±äº¬å¤§å­¦å¤§å­¦é™¢ åšå£«2å¹´

ç·åˆæ–‡åŒ–ç ”ç©¶ç§‘ã€€(æ¸‹è°·é§’å ´ã‚­ãƒ£ãƒ³ãƒ‘ã‚¹)

å­¦æŒ¯DC2

æµ…äº• æ”¿å¤ªéƒŽ
#+END_CENTER

#+BEGIN_NOTE
#+BEGIN_ALIGNRIGHT
Made by guicho2.71828 (Masataro Asai)
#+END_ALIGNRIGHT
#+END_NOTE
#+END_outline-text-1

* Deep Neural Networks

äººå·¥ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³(1944), ç¬¬1æœŸ AIãƒãƒ–ãƒ« (60-70s), ç¬¬2æœŸ (80s), ãã—ã¦ä»Š

[[sjpg:deeplearning]]

** èªçŸ¥ã‚¿ã‚¹ã‚¯ã§äººé–“ã«åŒ¹æ•µã™ã‚‹ç²¾åº¦

[[png:dl-image-task]]

** èªçŸ¥ã‚¿ã‚¹ã‚¯ã§äººé–“ã«åŒ¹æ•µã™ã‚‹ç²¾åº¦

[[png:dl-nlp-task]]

** ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆã®å½¹å‰²

#+BEGIN_CENTER
ã€Œç›´æ„Ÿçš„ãªã€å•é¡Œã‚’è§£ã *é–¢æ•°* ã‚’å­¦ç¿’ã™ã‚‹ã“ã¨
#+END_CENTER

+ æ±‚ã‚ã‚‹ã¹ãé–¢æ•° $y^*=f^*(x)$
+ NNãŒè¡¨ã™é–¢æ•°ã€€ $y=f(x)$
+ â†’ é–¢æ•°ã®èª¤å·® $||y-y^*||$ ã‚’æœ€å°åŒ–ã™ã‚‹æœ€é©åŒ–å•é¡Œ

| ã‚¿ã‚¹ã‚¯       | å…¥åŠ›x      | å‡ºåŠ›y                      |
|--------------+------------+----------------------------|
| ç”»åƒåˆ†é¡ž     | ç”»åƒ       | ãƒ©ãƒ™ãƒ«(è»Šã€ãƒã‚³ã€çŒ¿ãƒ»ãƒ»ãƒ») |
| ç¿»è¨³         | æ–‡ç«        | æ–‡ç«                        |
| æœªæ¥äºˆæ¸¬     | ãƒ•ãƒ¬ãƒ¼ãƒ åˆ— | æ¬¡ã®ãƒ•ãƒ¬ãƒ¼ãƒ                |

** NNã¯è¤‡é›‘ãªå•é¡Œã‚’é­”æ³•ã®ã‚ˆã†ã«è§£ãã“ã¨ãŒå‡ºæ¥ã‚‹

#+BEGIN_LARGER
ãªãœãªã‚‰

#+BEGIN_indent
  + äººé–“ã¯è³¢ãã¦ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã§å‹•ã ã—ã€
  + ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã‚ã‚‹ = è³¢ã•ã®è¨¼æ˜Ž ã ã—ã€
  + è³¢ã‘ã‚Œã°ä½•ã§ã‚‚å‡ºæ¥ã¦å½“ç„¶ ã ã—ã€
  + å°†æ¥ã¯ã‚·ãƒ³ã‚®ãƒ¥ãƒ©ãƒªãƒ†ã‚£ã«æº¢ã‚Œã¦ã¦å½“ç„¶ã€‚
  + ...
  + ãƒã‚¡?
#+END_indent
#+END_LARGER

** 

[[png:dl-silver-bullet]]

** NNã¯è¤‡é›‘ãªå•é¡Œã‚’é­”æ³•ã®ã‚ˆã†ã«è§£ãã“ã¨ãŒã§ãã‚‹?

#+BEGIN_CONTAINER-FLUID
#+BEGIN_ROW-FLUID
#+BEGIN_SPAN8
+ *å‡ºæ¥ã‚‹æ´¾ã®æ„è¦‹:*
+ äººé–“ã¯è³¢ãã¦ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã§å‹•ã
+ ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ = è³¢ã„
+ è³¢ã„æ©Ÿæ¢°ã¯ã‚¹ã‚´ã‚¤ã‹ã‚‰ãƒ‹ãƒ¥ãƒ¼ãƒ­ãƒ³ã 
+ è„³ç§‘å­¦ã§ã‚·ãƒ³ã‚®ãƒ¥ãƒ©ã£ã¡ã‚ƒã†ãœï¼
+ *å‡ºæ¥ãªã„æ´¾ã®æ„è¦‹:*
+ ãƒ’ãƒˆãƒ‡ã‚„ãƒ—ãƒ©ãƒŠãƒªã‚¢ã‚‚ç¥žçµŒç³»ã‚’æŒã¤ãŒè³¢ã„ã‹??
+ *Do you /really/ believe that humanity is smart?*
#+END_SPAN8
#+BEGIN_SPAN4
[[sjpg:trump]]

[[spng:mizuho]]
#+BEGIN_ALIGNRIGHT
â€» ç”»åƒã¯ã‚¤ãƒ¡ãƒ¼ã‚¸
#+END_ALIGNRIGHT
#+END_SPAN4
#+BEGIN_SPAN12
  + *The sad reality recently told us: People are not necessarily smart.â†‘*
#+END_SPAN12
#+END_ROW-FLUID
#+END_CONTAINER-FLUID


** No Silver Bullet: NNã§è¤‡é›‘ãªå•é¡Œã‚’é­”æ³•ã®ã‚ˆã†ã«è§£ãã“ã¨ã¯ã§ããªã„ãƒ»ãƒ»ãƒ»ã¨æ€ã‚ã‚Œã‚‹

+ å‡ºæ¥ã‚‹æ´¾ã®ã‚‚ã†å°‘ã—ãƒžã‚·ãªæ„è¦‹:
  + NN ã¯ Turingå®Œå…¨, ã‚¢ãƒŠãƒ­ã‚°NNã¯ Super Turing (Siegelmann, 95, Science)
  + äºŒæ®µä»¥ä¸Šã®NNã¯ ååˆ†ãªæ•°ã®ãƒŽãƒ¼ãƒ‰ãŒã‚ã‚Œã° ã©ã‚“ãªé–¢æ•°ã§ã‚‚è¡¨ç¾ã™ã‚‹ã“ã¨ãŒã§ãã‚‹

+ *å‡ºæ¥ãªã„æ´¾ã®ã‚‚ã†å°‘ã—çœŸé¢ç›®ãªåè«–*:
  + *è¡¨ç¾ã§ãã‚‹ != å­¦ç¿’ã§ãã‚‹*
  + *æ§‹é€ ã®å˜ç´”ãªé–¢æ•°ã—ã‹å­¦ç¿’ã§ããªã„*
    + *Gradient Descent ã®äºœç¨®ã§è§£ã‘ã‚‹ã‚ˆã†ãªé–¢æ•°*
    + *å±€æ‰€è§£ã¯å¤§åŸŸæœ€é©è§£ã§ã‚ã‚‹??*

** Gradient Descent (å†æ€¥é™ä¸‹æ³•)

å‚¾ãã®å¤§ãã„æ–¹å‘ã«å‘ã‹ã£ã¦é€²ã‚€

[[spng:gradient-descent]]

*æœ€é©è§£ã§ãªã„ã¨ã“ã‚ã«åˆ°é”ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŒã€*

*å±€æ‰€è§£ã¯ã»ã¼ç¢ºå®Ÿã«å¤§åŸŸæœ€é©è§£ã§ã‚ã‚‹ ã¨ã„ã†ä»®å®šã§ç„¡è¦–ã—ã¦ã„ã‚‹*

#+BEGIN_NOTE
SGDã§ã‚‚åŸºæœ¬çš„ãªæƒ³å®šã¯ä¸€ç·’
#+END_NOTE

** é€²åŒ–è¨ˆç®—ãªã©ã§è§£ã‹ã‚Œã‚‹Rastriginé–¢æ•° (ä¾‹)

[[sjpg:rastrigin]]

èª¤ã£ãŸå±€æ‰€è§£ã«è½ã¡ãŸå ´åˆã«ã©ã†ã‚„ã£ã¦è„±å‡ºã™ã‚‹ã‹?

â†’ ç‰©ä½“èªè­˜ã®é–¢æ•°ã¯ã“ã†ã„ã†å½¢ã‚’ã—ã¦ã„ãªã„ã€ã¨ä»®å®šã—ã¦ã„ã‚‹

** éŠ€ã®å¼¾ã¯ãªã„: NNã§è¤‡é›‘ãªå•é¡Œã‚’é­”æ³•ã®ã‚ˆã†ã«è§£ãã“ã¨ã¯ã§ããªã„ãƒ»ãƒ»ãƒ»ã¨æ€ã‚ã‚Œã‚‹

+ å‡ºæ¥ãªã„æ´¾ã®ã‚‚ã†å°‘ã—çœŸé¢ç›®ãªåè«–2:
  + *èªçŸ¥ã‚¿ã‚¹ã‚¯ã¨æ¯”ã¹ã€è«–ç†æ€è€ƒã‚¿ã‚¹ã‚¯ã¯äººé–“ã«ã‚‚é›£ã—ã„*
    + *äººé–“ã®ç‰©ä½“èªè­˜: 1ç§’ä»¥ä¸‹*
    + *å¤§å­¦å…¥è©¦æ•°å­¦ã®è¨¼æ˜Žå•é¡Œ: 25åˆ†*
  + *è«–ç†æ€è€ƒã‚¿ã‚¹ã‚¯ã¯è¨ˆç®—é‡ç†è«–çš„ã«å›°é›£ãªå•é¡ŒãŒå¤šæ•°*
    + *NPå›°é›£ä»¥ä¸Š: æœ€æ‚ªæŒ‡æ•°æ™‚é–“*
    + *â† å­¦ç¿’ã«æŒ‡æ•°æ™‚é–“ã‹ã‹ã‚‹ = è§£ã‘ãªã„ã®ã¨åŒã˜*

** å­¦ç¿’ãŒçµ‚ã‚ã‚‹ã®ã¯

[[sjpg:åˆ©æ ¹å·]]

** 

#+BEGIN_XLARGE
#+BEGIN_CENTER
ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆã¯

éŠ€ã®å¼¾ã§ã¯ãªã„

å¾“ã£ã¦ã€ãƒ–ãƒ¼ãƒ ã§ã¯ã‚ã‚‹ãŒãƒ»ãƒ»ãƒ»
#+END_CENTER
#+END_XLARGE

** 

[[sjpg:fukashigi]]

* AI Topics -- ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã¸ã®ã‚¤ãƒ³ãƒˆãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³(å†ã³)

#+BEGIN_QUOTE
ã€Œã“ã‚ŒãŒDLã®æ¬¡ã«ã‚ã‚‹ã‚‚ã†ã²ã¨ã¤ã®äººå·¥çŸ¥èƒ½ã ã€
#+END_QUOTE

** èª°?

 #+BEGIN_CONTAINER-FLUID
 #+BEGIN_ROW-FLUID
 #+BEGIN_SPAN6
 [[png:astro/1]]
 #+END_SPAN6
 #+BEGIN_SPAN6
 [[png:rescue/1]]
 #+END_SPAN6
 #+END_ROW-FLUID
 #+END_CONTAINER-FLUID

  #+BEGIN_RESUME
  And let me introduce these robots.
  The guy in the left is Astro boy.
  #+END_RESUME

*** èª°?

 #+BEGIN_CONTAINER-FLUID
 #+BEGIN_ROW-FLUID
 #+BEGIN_SPAN6
 [[png:astro/2]]
 #+END_SPAN6
 #+BEGIN_SPAN6
 [[png:rescue/1]]
 #+END_SPAN6
 #+END_ROW-FLUID
 #+END_CONTAINER-FLUID

 #+BEGIN_RESUME
 As you know, he is a famous manga superhero invented by Tezuka Osamu in 50s,
 #+END_RESUME

*** èª°?

  #+BEGIN_CONTAINER-FLUID
  #+BEGIN_ROW-FLUID
  #+BEGIN_SPAN6
  [[png:astro/final]]
  #+END_SPAN6
  #+BEGIN_SPAN6
  [[png:rescue/1]]
  #+END_SPAN6
  #+END_ROW-FLUID
  #+END_CONTAINER-FLUID

 #+BEGIN_RESUME
 and he can think, hear, speak, act. he also has emotions.
 #+END_RESUME

*** èª°?

  #+BEGIN_CONTAINER-FLUID
  #+BEGIN_ROW-FLUID
  #+BEGIN_SPAN6
  [[png:astro/final]]
  #+END_SPAN6
  #+BEGIN_SPAN6
  [[png:rescue/2]]
  #+END_SPAN6
  #+END_ROW-FLUID
  #+END_CONTAINER-FLUID

 #+BEGIN_RESUME
  In contrast, the guy in the right is a real robot that is actually in use @ fukuoka prefecture for the rescue purpose..
  His name is T-52 Enryu, developped by a Japanese company Temzak.
  He is huge and powerful -- about 4 meters in height and can carry things which is as heavy as 500kg.
  Well, so, in a sense, he is also a superhero in the real disastrous situation.
 #+END_RESUME

*** èª°?

  #+BEGIN_CONTAINER-FLUID
  #+BEGIN_ROW-FLUID
  #+BEGIN_SPAN6
  [[png:astro/final]]
  #+END_SPAN6
  #+BEGIN_SPAN6
  [[png:rescue/3]]
  #+END_SPAN6
  #+END_ROW-FLUID
  #+END_CONTAINER-FLUID

 #+BEGIN_RESUME
 But does he have feelings or can he think? Can he even move around by his own?
 #+END_RESUME

*** èª°?

  #+BEGIN_CONTAINER-FLUID
  #+BEGIN_ROW-FLUID
  #+BEGIN_SPAN6
  [[png:astro/final]]
  #+END_SPAN6
  #+BEGIN_SPAN6
  [[png:rescue/final]]
  #+END_SPAN6
  #+END_ROW-FLUID
  #+END_CONTAINER-FLUID

 #+BEGIN_RESUME
 No. It requires full human intervention --- it is indeed operated by a
 driver who gets in or by a remote control. It is more like a
 super-sophisticated shovel car.
 #+END_RESUME

** å®Ÿéš›ã®å¤§è¦æ¨¡ç½å®³ã§ã¯éžå®Ÿç”¨çš„ --- æ“ç¸¦å£«ãŒè¶³ã‚Šãªã„!

 #+BEGIN_CONTAINER-FLUID
 #+BEGIN_ROW-FLUID
 #+BEGIN_SPAN2
 [[png:rescue]]
 [[png:rescue]]
 [[png:rescue]]
 [[png:silent]]
 #+END_SPAN2
 #+BEGIN_SPAN10
 [[jpg:static/tsunami]]
 #+END_SPAN10
 #+END_ROW-FLUID
 #+END_CONTAINER-FLUID

 #+BEGIN_LARGER
 #+BEGIN_ALIGNRIGHT
 + ãã®ã¾ã¾ã§ã¯å½¹ã«ç«‹ãŸãªã„!
 #+END_ALIGNRIGHT
 #+END_LARGER

 #+BEGIN_RESUME
 Now the problem is : It's ok in small accidents but is impractical in the real, massive 
 natural disaster which frequently occurs in Japan.
 The key resource is human ---
 These special purpose vehicles require human intervention,
 thus they are useless without trained operators.
 #+END_RESUME

*** æ“ç¸¦å£«ã‚’å¢—ã‚„ã›ãªã„ -- Human Resource and Training

 #+BEGIN_CONTAINER-FLUID
 #+BEGIN_ROW-FLUID
 #+BEGIN_SPAN4
  [[png:rescue/1]]
 #+END_SPAN4
 #+BEGIN_SPAN8

   + âœ˜ /æ™‚é–“/ ãŒã‹ã‹ã‚‹ :: è¨“ç·´ã« ï¼ž100æ™‚é–“, *å¿…è¦ãªæ™‚ã ã‘å¢—ã‚„ã™* ã®ã¯ä¸å¯èƒ½
   + âœ˜ /ï¿¥ï¿¥ï¿¥ï¿¥/ ãŒã‹ã‹ã‚‹ :: è¨“ç·´å®˜ã€è¨“ç·´å ´æ‰€ã€è¨“ç·´ç”¨å…·
   + âœ˜ æŠ€è¡“ã¯ /ç¶­æŒãŒé‡è¦/ :: å®šæœŸçš„ãªå†è¨“ç·´ã€é•·æœŸçš„ã‚³ã‚¹ãƒˆã€ã•ã‚‰ãªã‚‹ãƒžãƒ‹ãƒ¼
   + âœ˜ å¹³æ™‚ã¯ /ç„¡é§„/ ãªæŠ€è¡“ :: æ™®æ®µã¯æ„å‘³ãŒãªã„ -- ç„¡é§„ãªãƒžãƒ‹ãƒ¼!
 #+END_SPAN8
 #+END_ROW-FLUID
 #+END_CONTAINER-FLUID

 #+BEGIN_RESUME
 In a natural disaster, we need as many experienced operators as possible.
 However, it is virtually impossible due to several reasons. 

 First, training takes time.
 It is impossible to quickly increase the number of operators as needed, at the time of disaster.

 Second, the money matters.
 Training a person costs a lot of money, including: the cost of maintaining
 a training center, the cost of additional vehicles for training, the cost
 of training the trainers, wages for trainers, etc.

 Third, Skills need to be updated and maintained.
 You know, how about preparing the large number of operators in advance?
 No, the society cannot torelate the cost of keep training them.
 Operators may lose the skills and skills may become outdated.

 Finally, in a normal situation, those skills are useless.
 It forces the society to waste a great amount of extra money.
 #+END_RESUME

** ã ã‹ã‚‰ã“ã: è‡ªå‹•ãƒ—ãƒ©ãƒ³ãƒŠ Automated Planner

 [[png:planning/1]]

 #+BEGIN_RESUME
 ç ”ç©¶ãƒ†ãƒ¼ãƒžã®ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã¯ã€ãƒ­ãƒœãƒƒãƒˆã«ã€äººé–“ã®åŠ©ã‘ã‚’å€Ÿã‚Šãšã€ã„ã‹ã«è‡ªå¾‹ã—ã¦è¡Œå‹•ã•ã›ã‚‹ã‹ã‚’æ‰±ã„ã¾ã™ã€‚
 ã“ã‚Œã‚’ãƒ¢ãƒ‡ãƒ«åŒ–ã—ãŸãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°å•é¡Œã¯ã€å…·ä½“çš„ãªè¡Œå‹•ã®åˆ—ã‚’æ±‚ã‚ã‚‹ çµ„åˆã›æœ€é©åŒ–å•é¡Œã§ã™ã€‚

 ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°å•é¡Œã®ã‚¿ã‚¹ã‚¯ã¯ã€
 ã‚»ãƒ³ã‚µãƒ¼ã‹ã‚‰åˆæœŸçŠ¶æ…‹ã¨ã‚´ãƒ¼ãƒ«ã‚’å—ã‘å–ã£ã¦ã€è¢«ç½è€…ã‚’åŠ©ã‘ã‚‹æ­£ã—ã„æ‰‹é †ã‚’å‡ºåŠ›ã™ã‚‹ã“ã¨ã§ã™ã€‚

 ãŸã¨ãˆã°ã€ã“ã®å›³ã§ã¯ç”·æ€§ãŒç“¦ç¤«ã«åŸ‹ã¾ã£ã¦åŠ©ã‘ã‚’æ±‚ã‚ã¦ã„ã¾ã™ã€‚
 ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°æ©Ÿèƒ½ã®ã‚ã‚‹ãƒ­ãƒœãƒƒãƒˆã¯ã€ã‚³ãƒ¬ã«å¯¾ã—ã¦ã€Œç”·æ€§ã‚’åŠ©ã‘ã‚ˆã€ã¨ã„ã†å¤§ã¾ã‹ãªæŒ‡ç¤ºã‚’å—ã‘ã¾ã™ã€‚
 #+END_RESUME

** ã ã‹ã‚‰ã“ã: è‡ªå‹•ãƒ—ãƒ©ãƒ³ãƒŠ Automated Planner

 [[png:planning/2]]

 #+BEGIN_RESUME
 æŒ‡ç¤ºã®å†…å®¹ã«ã¯ã€å›³ã®ã‚ˆã†ã«åˆæœŸçŠ¶æ…‹ã¨ã‚´ãƒ¼ãƒ«ã€è¨±å¯ã•ã‚ŒãŸè¡Œå‹•ã®ãƒªã‚¹ãƒˆãŒå…¥ã£ã¦ã„ã¾ã™ã€‚
 ãƒ­ãƒœãƒƒãƒˆã¯ã€è‡ªå‹•ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã«ã‚ˆã‚Šã€äººé–“ã®ä»£ã‚ã‚Šã«é©åˆ‡ãªè¡Œå‹•ã‚’çµ„ã¿ç«‹ã¦ã¦ã€ã‚´ãƒ¼ãƒ«ã‚’è‡ªå‹•ã§é”æˆã—ã¾ã™ã€‚
 #+END_RESUME

** ã ã‹ã‚‰ã“ã: è‡ªå‹•ãƒ—ãƒ©ãƒ³ãƒŠ Automated Planner

 [[png:planning/final]]

 #+BEGIN_RESUME
 ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã¯æ±Žç”¨ãªæž çµ„ã¿ãªã®ã§ã€ç½å®³æ•‘åŠ©ä»¥å¤–ã«ã‚‚æ§˜ã€…ãªå•é¡Œã«é©ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
 ç¾å®Ÿã®å¿œç”¨ä¾‹ã§ã¯ã€Œå®‡å®™æŽ¢æŸ»æ©Ÿé‹è¡Œå•é¡Œã€ã‚„ã€Œä¼æ¥­ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è„†å¼±æ€§å•é¡Œã€ã‚‚è¡¨ç¾ã§ãã¾ã™ã€‚

 ã“ã®ã‚ˆã†ã«ã€ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã¯ã€é›£ã—ã„å•é¡Œã‚’æ±Žç”¨æ€§ã‚’å¤±ã‚ãšã«è§£ãã“ã¨ã‚’ç›®æŒ‡ã—ã¾ã™ã€‚
 #+END_RESUME

 # è‡ªå‹•é‹è»¢äº‹æ•…:
 # ãƒãƒªã‚·ãƒ¼ãŒæ±ºã¾ã£ã¦ã„ãªã„ãªã‚‰ãã†ã„ã†ã‚‚ã®ã¯ä½œã‚‹ã¹ãã§ã¯ãªã„
 # å±é™ºã 

 # ã—ã‹ã—è‡ªå‹•é‹è»¢ã¯è‡ªåˆ†ã®æ‰±ã†ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã¨ã¯é•ã†ã®ã§å®Ÿã¯å›°ã‚‰ãªã„

 # ã‚´ãƒ¼ãƒ«è¨­å®šã¯äººé–“ãŒã‚„ã‚Œã°ã„ã„
 # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’æ±ºã‚ãŸä¸Šã§
 # å…¨åŠ›ã§è€ƒãˆã‚‹ã®ãŒãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã®æŠ€è¡“
 # åŠ¹ç”¨é–¢æ•°ã‚’æ±ºã‚ã‚‹ã®ã¯äººé–“
 # ã„ã‹ã«ãã‚Œã‚’å®Ÿç¾ã™ã‚‹ã‹
 # ã‚ãã¾ã§å‘½ä»¤ã«å¾“ã†ãƒ­ãƒœãƒƒãƒˆã§ã‚ã‚‹ã“ã¨ã‚’å¼·èª¿

 # ãƒ‰ãƒ¡ã‚¤ãƒ³ã¯æ¶ˆã™
 # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
 # 
 # coreã¾ã§ã¯å®Ÿä¾‹
 # ç½å®³æ´åŠ©ã¯å°†æ¥
 # å®Œå…¨ã«åˆ†é›¢
 # 
 # æŽƒé™¤ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚’ãƒ¡ã‚¤ãƒ³ã«

 # ** ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã¨ã¯?
 # 
 # [[png:planning-4room]]

 # #+BEGIN_RESUME
 # åŒã˜æŽƒé™¤ãƒ‰ãƒ¡ã‚¤ãƒ³ã®4éƒ¨å±‹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚‚è¡¨ç¾ã§ãã¾ã™ã—ã€
 # ç¾å®Ÿã®å¿œç”¨ä¾‹ã§ã¯ã€Œå®‡å®™æŽ¢æŸ»ãƒ‰ãƒ¡ã‚¤ãƒ³ã€ã‚‚è¡¨ç¾ã§ãã¾ã™ã€‚
 # 
 # ã“ã®ã‚ˆã†ã«ã€ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã¯ã€é›£ã—ã„å•é¡Œã‚’æ±Žç”¨æ€§ã‚’å¤±ã‚ãšã«è§£ãã“ã¨ã‚’ç›®æŒ‡ã—ã¾ã™ã€‚
 # 
 # ä»®ã«å°†æ¥ã€å†™çœŸã®ã‚ˆã†ãªæ•‘åŠ©ãƒ­ãƒœãƒƒãƒˆã«ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ã‚½ãƒ«ãƒã‚’çµ„ã¿è¾¼ã‚ã°ã€
 # è¢«ç½è€…ã‚’ç™ºè¦‹ã—ãŸæ™‚ã«é©åˆ‡ãªè¡Œå‹•ã‚’è‡ªã‚‰é¸æŠžã§ãã‚‹ã‚ˆã†ã«ãªã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚
 # #+END_RESUME

** AIã®ä½¿ã„ãƒ‰ã‚³ãƒ­  :noexport:

 + äººã§ã¯ä¸å¯èƒ½ãªä½œæ¥­ã®ä»£æ›¿ :: å±é™ºãªç’°å¢ƒ, å®‡å®™ç©ºé–“ãƒ»æ·±æµ·, 24æ™‚é–“å¯¾å¿œ, ãƒžã‚¤ã‚¯ãƒ­ç§’å¿œç­”
 + ã‚³ã‚¹ãƒˆã®ã‹ã‹ã‚‹å°‚é–€æŠ€å¸«ã®ä»£æ›¿ãƒ»è‡ªå‹•åŒ– :: æ©Ÿæ¢°å·¥ä½œ, äººå·¥è¡›æ˜Ÿé‹å–¶(å°‚é–€å®¶ä¼šè­°ã®æ™‚çµ¦ãŒé«˜ã„!)
 + ãƒŸã‚¹ã®è¨±ã•ã‚Œãªã„å®Œç’§ãªç†è«–ä¿è¨¼ã®æ±‚ã‚ã‚‰ã‚Œã‚‹å•é¡Œã®æ±‚è§£ :: åŠå°Žä½“ã®ãƒã‚°æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ (ç”Ÿç”£ã‚’å§‹ã‚ã‚‹ã¨æ­¢ã‚ã‚‰ã‚Œãªã„)

** AIã¨è‡ªå‹•ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚° ã®ä½ç½®ã¥ã‘ -- /ç†è«–/ ã¨ /å®Ÿå¿œç”¨/ ã®ä¸­é–“  :noexport:

 ç·‘ã¯ /ç†è«–/ ã€ã‚ªãƒ¬ãƒ³ã‚¸ã¯ /å®Ÿå¿œç”¨/ ã€ AI ã¯ãã®æ©‹æ¸¡ã— (ã©ã‚Œã¨ã‚‚ã‹ã¶ã‚‰ãªã„éƒ¨åˆ†ã‚‚ã‚ã‚‹)

 #+BEGIN_RESUME
 Automated Planning is a branch of Aritificial Intelligence. 

 It shares a lot of technology with Operations Research and Theoretical
 Computer Science, and is considered a bridge between pure theory and
 pure applications.
 #+END_RESUME

 [[png:planning2]]

* ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°å•é¡Œ (æ±ºå®šçš„,å®Œå…¨æƒ…å ±) -- Blocksworld

[[png:plan]]

** ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ = æ¡ä»¶ä»˜ãçŠ¶æ…‹é·ç§»

#+BEGIN_CENTER
#+BEGIN_XLARGE
(move ?X ?Y)
#+END_XLARGE
#+END_CENTER


#+BEGIN_CENTER
å¤‰æ•° *?X*, *?Y* ãªã©ã«å€¤ *BLOCK-A*, *BLOCK-B* ãªã©ã‚’é©ç”¨ã—ã¦ä½¿ã†

*å‰ææ¡ä»¶* *è¿½åŠ åŠ¹æžœ* *å‰Šé™¤åŠ¹æžœ* ã§æ§‹æˆã•ã‚Œã‚‹
#+END_CENTER
#+BEGIN_QUOTE
*å‰ææ¡ä»¶*

(clear *?X*) : ç©ã¿æœ¨ *?X* ã®ä¸Šã«ä½•ã‚‚ãªã (1)

(clear *?Y*) : ç©ã¿æœ¨ *?Y* ã®ä¸Šã«ã‚‚ä½•ã‚‚ãªã„ (2) ã¨ãã«ã€

*è¿½åŠ åŠ¹æžœ*

â‡’ (on *?X* *?Y*) : *?X* ãŒ *?Y* ã®ä¸Šã«ç§»å‹•ã™ã‚‹ã€‚(3)

*å‰Šé™¤åŠ¹æžœ*

â‡’ (not (clear *?Y*)) : *?Y* ã¯ clear ã§ã¯ãªããªã‚‹ã€‚(4)
#+END_QUOTE

** *PDDL* : Planning Domain Description Language

ç¾åœ¨ã‚‚ International Planning Competition ã®å…¥åŠ›å½¢å¼ã¨ã—ã¦ä½¿ã‚ã‚Œã¦ã„ã‚‹ã€‚

#+BEGIN_CONTAINER-FLUID
#+BEGIN_ROW-FLUID
#+BEGIN_SPAN2

#+END_SPAN2
#+BEGIN_SPAN6
#+BEGIN_SRC lisp
(:action move
 :parameters (?X ?Y)
 :preconditions
   (and (clear ?X)   ; (1)
        (clear ?Y))  ; (2)

 :effect
   (and (on ?X ?Y)   ; (3)
        (not         ; (4)
         (clear ?Y))))
#+END_SRC
#+END_SPAN6
#+BEGIN_SPAN2

#+END_SPAN2
#+END_ROW-FLUID
#+END_CONTAINER-FLUID

#+BEGIN_NOTE
å®‡å®™æŽ¢æŸ»æ©Ÿ NASA DS1 ä¸Šã® Remote Agent è‡ªå‹•èˆªè¡Œã‚·ã‚¹ãƒ†ãƒ  ã§ã‚‚
 "DDL" ã¨ã„ã†åã§ ä¼¼ãŸã‚ˆã†ãªè¨˜è¿°è¨€èªžãŒã‚ã£ãŸã‚ˆã†ã 
#+END_NOTE

** ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚° = ã‚°ãƒ©ãƒ•æŽ¢ç´¢

*ãƒŽãƒ¼ãƒ‰* : çŠ¶æ…‹ = å‘½é¡Œã®é›†åˆ â‡’ =(on A B)=, =(clear A)= ãªã©

*è¾º*     : ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ â‡’ =(move A B)= ç­‰

[[png:graph]]

# #+BEGIN_CONTAINER-FLUID
# #+BEGIN_ROW-FLUID
# #+BEGIN_SPAN6
# # + ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯æŽ¢ç´¢ A*
# # + State-of-the-Art *1
# #+END_SPAN6
# #+BEGIN_SPAN6
# # #+attr_html: :width 50%
# #+END_SPAN6
# #+END_ROW-FLUID
# #+END_CONTAINER-FLUID

#+BEGIN_NOTE
*1 [Helmert, 2006] [Richter, 2010]
#+END_NOTE
  



** Q. ã¯ã‚„ã‚Šã®Deep Learningã¨ã®é•ã„ã¯?

 A. ãƒ¬ã‚¤ãƒ¤ãŒé•ã†

 #+BEGIN_CONTAINER-FLUID
 #+BEGIN_ROW-FLUID
 #+BEGIN_SPAN6
 *æ©Ÿæ¢°å­¦ç¿’ãƒ»Neural Networks* 
 
 for *èªè­˜ãƒ»åå°„*
 + å…¥åŠ› ã¯ *Subsymbolic*
   
   ç”»åƒã€éŸ³å£°ã€éžæ§‹é€ åŒ–ãƒ†ã‚­ã‚¹ãƒˆ
 + *1ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—*:
   
   ã€€ *_ç›´å¾Œ_ ã®è¡Œå‹•ã®æ±ºå®š*
   #+BEGIN_SMALLER
   Reflex Agent = è„Šé«„åå°„

   *ãƒ‘ãƒ–ãƒ­ãƒ•ã®çŠ¬* : é¤Œâ†’ã‚ˆã ã‚Œ

   *è‡ªå‹•é‹è»¢* : èµ¤ä¿¡å·,äºº â†’ æ­¢ã¾ã‚‹.

   *ãƒ•ã‚¡ãƒŠãƒƒã‚¯ç”£æ¥­ãƒ­ãƒœ* : ç”»åƒ â†’ ãƒ¢ãƒ¼ã‚¿å‡ºåŠ›

   *ç¿»è¨³* : æ–‡ç«  â†’ æ–‡ç« 
   #+END_SMALLER
   â˜º åŠ¹çŽ‡ã‚ˆã 1-to-1 mapping
   
   â˜¹ å˜ç´”ä½œæ¥­
 #+END_SPAN6
 #+BEGIN_SPAN6
 *æŽ¨è«–ãƒ»æŽ¢ç´¢*

 for *ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°ãƒ»ã‚²ãƒ¼ãƒ ãƒ»å®šç†è¨¼æ˜Ž*
 + å…¥å‡ºåŠ›ã¯ *Symbolic*
   
   è«–ç† ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ ãƒ«ãƒ¼ãƒ«
 + *>1000ã‚¿ã‚¤ãƒ ã‚¹ãƒ†ãƒƒãƒ—:*

   ã€€ *_æœªæ¥ã«æ¸¡ã‚‹_ æˆ¦ç•¥ã®æ±ºå®š*
   
   ã€€ (æˆ¦ç•¥ = è¡Œå‹•ã® *åˆ—ã‚„æœ¨*)
   #+BEGIN_SMALLER
   *ãƒ¬ã‚¹ã‚­ãƒ¥ãƒ¼ãƒ­ãƒœ* : ç¾å®Ÿ = é›£è§£ãƒ‘ã‚ºãƒ«

   *å›²ç¢,å°†æ£‹* : ã‚´ãƒ¼ãƒ« = å‹åˆ©

   *è¨¼æ˜Žå™¨* : ã‚´ãƒ¼ãƒ« = QED

   *ã‚³ãƒ³ãƒ‘ã‚¤ãƒ©* : å‘½ä»¤åˆ—ã®ç”Ÿæˆ
   #+END_SMALLER
   #+BEGIN_LARGER
   â˜º å¤šæ•°ã®è«–ç†ã®çµ„ã¿åˆã‚ã›
   #+END_LARGER
 #+END_SPAN6
 #+END_ROW-FLUID
 #+END_CONTAINER-FLUID

#+BEGIN_ALIGNRIGHT
AlphaGo = Subsymbolic (DLNNã«ã‚ˆã‚‹è©•ä¾¡é–¢æ•°ã®å­¦ç¿’) + Symbolic (UCT-MCTSã«ã‚ˆã‚‹æŽ¢ç´¢)
#+END_ALIGNRIGHT

#+BEGIN_NOTE
DLNN: Deep Learning Neural Network

UCT-MCTS: Monte Carlo Tree Search + Universal Confidence Bound applied on Trees
#+END_NOTE

* ä»Šæ—¥ã®ç™ºè¡¨ã® Motivation

#+BEGIN_CONTAINER-FLUID
#+BEGIN_ROW-FLUID
#+BEGIN_SPAN6
|                |         |
|----------------+---------|
| ç¬¬ä¸€æ¬¡AIãƒ–ãƒ¼ãƒ  | ~'70    |
| *ç¬¬ä¸€æ¬¡AIã®å†¬* | '70~'80 |
| ç¬¬äºŒæ¬¡AIãƒ–ãƒ¼ãƒ  | '80~    |
| *ç¬¬äºŒæ¬¡AIã®å†¬* | '90~    |
| ç¬¬ä¸‰æ¬¡AIãƒ–ãƒ¼ãƒ  | '2008~  |
| *ç¬¬ä¸‰æ¬¡AIã®å†¬??* | ????    |
#+END_SPAN6
#+BEGIN_SPAN6
+ ç¬¬äºŒæ¬¡AIã®å†¬ã®åŽŸå› :
  + *è«–ç†ã ã‘ã§å…¨ã¦ãŒè§£æ±ºã§ãã‚‹ã¨è€ƒãˆãŸ*
  + ç¾å®Ÿä¸–ç•Œ (ç‰©ä½“ã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³) ã®ãƒ©ãƒ™ãƒ«ä»˜ã‚’ðŸ‘å…¥åŠ›ã™ã‚‹å¿…è¦ãŒã‚ã£ãŸ
+ ç¬¬ä¸‰æ¬¡AIã®å†¬ã®ã‚ã‚Šãã†ãªåŽŸå› 
  + *å­¦ç¿’ã•ãˆã§ãã‚Œã°å…¨ã¦ãŒè§£æ±ºã§ãã‚‹ã¨è€ƒãˆãŸ?*
#+END_SPAN6
#+END_ROW-FLUID
#+END_CONTAINER-FLUID

** é«˜åº¦ã«çŸ¥çš„ãªæ©Ÿæ¢°ã‚’ä½œã‚‹ã«ã¯ â†’ DeepLearning + è«–ç†ã¨æŽ¨è«–

#+BEGIN_CENTER
#+BEGIN_CONTAINER-FLUID
#+BEGIN_ROW-FLUID
#+BEGIN_SPAN5
çŠ¬çŒ«ç¨‹åº¦ã®çŸ¥èƒ½ã‚’æŒã£ãŸ

*åå°„çš„ãªæ©Ÿæ¢°*
#+END_SPAN5
#+BEGIN_SPAN2
ã€€

vs

ã€€
#+END_SPAN2
#+BEGIN_SPAN5
ç›®æ¨™ã‚’é”æˆã™ã‚‹ãŸã‚ã«è«–ç†çš„ãª

*æˆ¦ç•¥ã‚’ç·´ã‚‹æ©Ÿæ¢°*

#+END_SPAN5
#+END_ROW-FLUID
#+END_CONTAINER-FLUID
#+END_CENTER

[[png:planning-deeplearning]]

* ã‚´ãƒ¼ãƒ«

#+BEGIN_XLARGE
#+BEGIN_CENTER
State of the Art Deep Learning ã¨

State of the Art Classical Planning ã‚’çµ„ã¿åˆã‚ã›ã‚‹
#+END_CENTER
#+END_XLARGE

#+BEGIN_ALIGNRIGHT
ã²ã¨ã¾ãšä¼‘æ†©
#+END_ALIGNRIGHT

* å”çªã§ã™ãŒå–ã£æŽ›ã‹ã‚Šã¨ã—ã¦

æ­»ã‚“ã§ã‚‹ã¨æ€ã£ã¦ãŸã‚»ãƒŸãŒå®Ÿã¯ç”Ÿãã¦ã¦

ã³ã£ãã‚Šã—ãŸã“ã¨ã¯ã‚ã‚Šã¾ã›ã‚“ã‹?

[[sjpg:semifinal]]

Credit: http://hukaimandara.jugem.jp/?eid=92

* Backgrounds

[[jpg:static/cicada]]

Credit: http://hukaimandara.jugem.jp/?eid=92


* Latent Space $L$ of an original state space $S$

#+BEGIN_QUOTE
Apparently very complex $S$ can be described by low-dimentional $L$
#+END_QUOTE

[[jpg:static/cicada]]

* Manifold Hypothesis

$x$: high dimensional vector in $S$, $z$ in manifold $L$

Data is concentrated around a low dimensional manifold

Hope finding a representation Z of that manifold.

http://www.deeplearningbook.org/ and VAE tutorial

[[png:static/manifold]]

* Manifold Hypothesis

$x$: high dimensional vector in $S$, $z$: manifold $L$

Data is concentrated around a low dimensional manifold

Hope finding a representation Z of that manifold.

http://www.deeplearningbook.org/ and VAE tutorial

[[png:static/manifold2]]

* How to obtain $L$?

+ PCA: Principal Component Analysis

+ */âœ˜/* Assumes a linear function

\[y = f(x) = Wx + b\]

* Neural Network

+ A framework for learning a *function* that maps input $x$ to output $y$

+ NN w/ $>2$ layers can learn arbitrary function (given enough neurons)

\[x = \sigma (Wx + b) \]

[[png:static/nn]]

* Autoencoder

#+BEGIN_CENTER
Unsupervised learning method which learns to 

*compress S* into *L* and *decompress back to S*
#+END_CENTER

#+BEGIN_CONTAINER-FLUID
#+BEGIN_ROW-FLUID
#+BEGIN_SPAN3

#+END_SPAN3
#+BEGIN_SPAN6
[[png:static/autoenc]]
#+END_SPAN6
#+BEGIN_SPAN3

#+END_SPAN3
#+END_ROW-FLUID
#+END_CONTAINER-FLUID

#+BEGIN_ALIGNRIGHT
â†’ equivalent to *PCA applied to nonlinear function*
#+END_ALIGNRIGHT

* Deep Autoencoder

Deep AE made available by various techniques

Stacked AE, pretraining, CNN, dropout, Batch-Normalization, GPU...

[[png:static/deep-ae]]


* Reinforcement Learning

*Policy function* $\pi(s)\mapsto a : S \rightarrow A$ -- returns action $a$ for state $s$

Agent always follows the policy function

*Optimal Policy* $\pi^* (s)$ : a policy that gives the highest reward

Goal: *Find/learn* the best approximation of $\pi^*$

Methods: Value-iteration, Policy-iteration, TD-learning âˆ‹ Q-learning

* Reinforcement Learning(RL) in Latent Space (e.g. Luck IROS14, AAAI16)

RL in $S$ is too difficult â†’ Apply RL to $L$ for speedup

\[x\in S, z \in L: \ x = f(z) \]

ã€€

mapping 62-DOF space â†’ 2D

[[png:static/latent-RL]]

# * Underlying belief:
# 
# #+BEGIN_QUOTE
# The real world is apparently complex, but in *almost all cases* they can be described by *only a few parameters*.
# #+END_QUOTE

* Deep Reinforcement Learning: DQN?

No, DQN is not using latent space representation

It represents Q-function by neural network

* Classical Planning 

_/âœ”/_ *Scalable, Highly-optimized solver* for complex combinatorial problems

_/âœ”/_ Guided by *domain-independent* heuristics

*/âœ˜/* *Requires an explicit encoding* of the real world, written by human

* Comparison

#+BEGIN_CONTAINER-FLUID
#+BEGIN_ROW-FLUID
#+BEGIN_SPAN6
#+BEGIN_CENTER
*Latent Reinforcement Learning*
#+END_CENTER

_/âœ”/_ Works on the *implicit encoding* of the real world

*/âœ˜/* Reasoning is limited to the *1-step future* of the current state

*/âœ˜/* guided by *instance-specific learned knowledge* (specific object, situation, goal)
#+END_SPAN6
#+BEGIN_SPAN6
#+BEGIN_CENTER
*Classical Planning*
#+END_CENTER

_/âœ”/_ *Scalable, Highly-optimized solver* for complex combinatorial problems

_/âœ”/_ Guided by *domain-independent* heuristics

*/âœ˜/* *Requires an explicit encoding* of the real world, written by human
#+END_SPAN6
#+END_ROW-FLUID
#+END_ROW-FLUID
#+END_CONTAINER-FLUID

* Goal of this project

|                      |                        |                        |
|----------------------+------------------------+------------------------|
| Man-made             |                        |                        |
| state representation | Reinforcement Learning | Classical Planning     |
|----------------------+------------------------+------------------------|
| Latent state         | Latent RL              | *Latent Planning*      |
| representation       |                        |                        |
|----------------------+------------------------+------------------------|
| Deep Latent state    |                        | *Deep Latent Planning* |
| (found by Deep AE)   |                        |                        |

* How?

Simply put: discretize $z$ into SAS variables

Below: results of encoding a MNIST image (784-variable) to 2 variables

Mapping the input image to latent space (encoding part)

[[png:static/vae-latent]]

* How?

Mapping the latent space to the actual image (decoding part)

[[png:static/vae-manifold]]

