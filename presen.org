#+title: 
#+author: Masataro Asai
#+include: "head.org"
#+LINK: img file:img/%s
#+LINK: png file:img/%s.png
#+LINK: jpg file:img/%s.jpg
#+LINK: svg file:img/%s.svg
#+LINK: spng file:img/static/%s.png
#+LINK: sjpg file:img/static/%s.jpg
#+LINK: ssvg file:img/static/%s.svg

#+BEGIN_outline-text-1
#+BEGIN_CENTER

# 田添

#+BEGIN_LARGER
*東京大学 総合文化研究科 広域科学専攻*

博士3年 学振DC2 -- *就活中!*
#+END_LARGER

# *AAAI, IJCAIなど国際学会の常連!*

#+BEGIN_LARGER
#+BEGIN_HTML
<ruby>浅井 政太郎<rt>あさい まさたろう</rt></ruby>
#+END_HTML
#+END_LARGER
#+BEGIN_XLARGE
Classical Planning

in Deep Latent Space:

*/記号を取り戻せ!/*
#+END_XLARGE

# 15分では到底終わらないので質疑の時間に食い込む(20分)
#+END_CENTER

#+BEGIN_NOTE
#+BEGIN_ALIGNRIGHT
Made by guicho2.71828 (Masataro Asai)
#+END_ALIGNRIGHT
#+END_NOTE
#+END_outline-text-1

* もくじ

#+BEGIN_XLARGE
深層学習 (AutoEncoder, VAE) -- は */解説の必要が無いはず/* なので
#+BEGIN_CENTER
記号的AIプランニング
#+END_CENTER
#+BEGIN_ALIGNRIGHT
の話からはじめます
#+END_ALIGNRIGHT
#+END_XLARGE

* もくじ                                                           :noexport:

+ 深層学習 -- は解説の必要はありませんね?
+ 記号的汎用AIプランニング
+ 深層学習 + AIプランニング

** 

 #+BEGIN_CENTER
 #+BEGIN_XLARGE
 199X年
 #+END_XLARGE
 #+END_CENTER

** 

 #+BEGIN_CENTER
 #+BEGIN_XLARGE
 AIは予算削減の冬に覆われた
 #+END_XLARGE
 #+END_CENTER

** 

 #+BEGIN_CENTER
 #+BEGIN_XLARGE
 あらゆる記号的AI研究者は

 絶滅したかに思えた
 #+END_XLARGE
 #+END_CENTER

** 

 #+BEGIN_XLARGE
 #+BEGIN_CENTER
 しかし 記号は

 死に絶えてはいなかった!
 #+END_CENTER
 #+END_XLARGE

** 

 #+BEGIN_CENTER
 #+BEGIN_XLARGE
 Classical Planning

 in Deep Latent Space:

 記号をとりもどせ!
 #+END_XLARGE
 #+END_CENTER

* 背景 -- AIプランニング

 #+BEGIN_CONTAINER-FLUID
 #+BEGIN_ROW-FLUID
 #+BEGIN_SPAN6
 [[png:astro/1]]
 #+END_SPAN6
 #+BEGIN_SPAN6
 [[png:rescue/1]]
 #+END_SPAN6
 #+END_ROW-FLUID
 #+END_CONTAINER-FLUID

** 誰?

 #+BEGIN_CONTAINER-FLUID
 #+BEGIN_ROW-FLUID
 #+BEGIN_SPAN6
 [[png:astro/1]]
 #+END_SPAN6
 #+BEGIN_SPAN6
 [[png:rescue/1]]
 #+END_SPAN6
 #+END_ROW-FLUID
 #+END_CONTAINER-FLUID

  #+BEGIN_RESUME
  And let me introduce these robots.
  The guy in the left is Astro boy.
  #+END_RESUME

*** 誰?

 #+BEGIN_CONTAINER-FLUID
 #+BEGIN_ROW-FLUID
 #+BEGIN_SPAN6
 [[png:astro/2]]
 #+END_SPAN6
 #+BEGIN_SPAN6
 [[png:rescue/1]]
 #+END_SPAN6
 #+END_ROW-FLUID
 #+END_CONTAINER-FLUID

 #+BEGIN_RESUME
 As you know, he is a famous manga superhero invented by Tezuka Osamu in 50s,
 #+END_RESUME

*** 誰?

  #+BEGIN_CONTAINER-FLUID
  #+BEGIN_ROW-FLUID
  #+BEGIN_SPAN6
  [[png:astro/final]]
  #+END_SPAN6
  #+BEGIN_SPAN6
  [[png:rescue/1]]
  #+END_SPAN6
  #+END_ROW-FLUID
  #+END_CONTAINER-FLUID

 #+BEGIN_RESUME
 and he can think, hear, speak, act. he also has emotions.
 #+END_RESUME

*** 誰?

  #+BEGIN_CONTAINER-FLUID
  #+BEGIN_ROW-FLUID
  #+BEGIN_SPAN6
  [[png:astro/final]]
  #+END_SPAN6
  #+BEGIN_SPAN6
  [[png:rescue/2]]
  #+END_SPAN6
  #+END_ROW-FLUID
  #+END_CONTAINER-FLUID

 #+BEGIN_RESUME
  In contrast, the guy in the right is a real robot that is actually in use @ fukuoka prefecture for the rescue purpose..
  His name is T-52 Enryu, developped by a Japanese company Temzak.
  He is huge and powerful -- about 4 meters in height and can carry things which is as heavy as 500kg.
  Well, so, in a sense, he is also a superhero in the real disastrous situation.
 #+END_RESUME

*** 誰?

  #+BEGIN_CONTAINER-FLUID
  #+BEGIN_ROW-FLUID
  #+BEGIN_SPAN6
  [[png:astro/final]]
  #+END_SPAN6
  #+BEGIN_SPAN6
  [[png:rescue/3]]
  #+END_SPAN6
  #+END_ROW-FLUID
  #+END_CONTAINER-FLUID

 #+BEGIN_RESUME
 But does he have feelings or can he think? Can he even move around by his own?
 #+END_RESUME

*** 誰?

  #+BEGIN_CONTAINER-FLUID
  #+BEGIN_ROW-FLUID
  #+BEGIN_SPAN6
  [[png:astro/final]]
  #+END_SPAN6
  #+BEGIN_SPAN6
  [[png:rescue/final]]
  #+END_SPAN6
  #+END_ROW-FLUID
  #+END_CONTAINER-FLUID

 #+BEGIN_RESUME
 No. It requires full human intervention --- it is indeed operated by a
 driver who gets in or by a remote control. It is more like a
 super-sophisticated shovel car.
 #+END_RESUME

** 実際の大規模災害では非実用的 --- 操縦士が足りない!              :noexport:

 #+BEGIN_CONTAINER-FLUID
 #+BEGIN_ROW-FLUID
 #+BEGIN_SPAN2
 [[png:rescue]]
 [[png:rescue]]
 [[png:rescue]]
 [[png:silent]]
 #+END_SPAN2
 #+BEGIN_SPAN10
 [[jpg:static/tsunami]]
 #+END_SPAN10
 #+END_ROW-FLUID
 #+END_CONTAINER-FLUID

 #+BEGIN_LARGER
 #+BEGIN_ALIGNRIGHT
 + そのままでは役に立たない!
 #+END_ALIGNRIGHT
 #+END_LARGER

 #+BEGIN_RESUME
 Now the problem is : It's ok in small accidents but is impractical in the real, massive 
 natural disaster which frequently occurs in Japan.
 The key resource is human ---
 These special purpose vehicles require human intervention,
 thus they are useless without trained operators.
 #+END_RESUME

*** 操縦士を増やせない -- Human Resource and Training

 #+BEGIN_CONTAINER-FLUID
 #+BEGIN_ROW-FLUID
 #+BEGIN_SPAN4
  [[png:rescue/1]]
 #+END_SPAN4
 #+BEGIN_SPAN8

   + ✘ /時間/ がかかる :: 訓練に ＞100時間, *必要な時だけ増やす* のは不可能
   + ✘ /￥￥￥￥/ がかかる :: 訓練官、訓練場所、訓練用具
   + ✘ 技術は /維持が重要/ :: 定期的な再訓練、長期的コスト、さらなるマニー
   + ✘ 平時は /無駄/ な技術 :: 普段は意味がない -- 無駄なマニー!
 #+END_SPAN8
 #+END_ROW-FLUID
 #+END_CONTAINER-FLUID

 #+BEGIN_RESUME
 In a natural disaster, we need as many experienced operators as possible.
 However, it is virtually impossible due to several reasons. 

 First, training takes time.
 It is impossible to quickly increase the number of operators as needed, at the time of disaster.

 Second, the money matters.
 Training a person costs a lot of money, including: the cost of maintaining
 a training center, the cost of additional vehicles for training, the cost
 of training the trainers, wages for trainers, etc.

 Third, Skills need to be updated and maintained.
 You know, how about preparing the large number of operators in advance?
 No, the society cannot torelate the cost of keep training them.
 Operators may lose the skills and skills may become outdated.

 Finally, in a normal situation, those skills are useless.
 It forces the society to waste a great amount of extra money.
 #+END_RESUME

** 自律行動のための自動プランナ (≠ モータ制御)

 [[png:planning/1]]

 #+BEGIN_RESUME
 研究テーマのプランニングは、ロボットに、人間の助けを借りず、いかに自律して行動させるかを扱います。
 これをモデル化したプランニング問題は、具体的な行動の列を求める 組合せ最適化問題です。

 プランニング問題のタスクは、
 センサーから初期状態とゴールを受け取って、被災者を助ける正しい手順を出力することです。

 たとえば、この図では男性が瓦礫に埋まって助けを求めています。
 プランニング機能のあるロボットは、コレに対して「男性を助けよ」という大まかな指示を受けます。
 #+END_RESUME

** 自律行動のための自動プランナ (≠ モータ制御)

 [[png:planning/2]]

 #+BEGIN_RESUME
 指示の内容には、図のように初期状態とゴール、許可された行動のリストが入っています。
 ロボットは、自動プランニングにより、人間の代わりに適切な行動を組み立てて、ゴールを自動で達成します。
 #+END_RESUME

** 自律行動のための自動プランナ (≠ モータ制御)

 [[png:planning/final]]

 #+BEGIN_RESUME
 プランニングは汎用な枠組みなので、災害救助以外にも様々な問題に適用することができます。
 現実の応用例では「宇宙探査機運行問題」や「企業ネットワーク脆弱性問題」も表現できます。

 このように、プランニングは、難しい問題を汎用性を失わずに解くことを目指します。
 #+END_RESUME

** AIプランニングの */Killer App/*


#+BEGIN_CONTAINER-FLUID
#+BEGIN_ROW-FLUID
#+BEGIN_SPAN7
#+BEGIN_LARGER
+ 人が高価or不可能な作業 :: 原発, 宇宙空間, 火星, 深海
+ 正しさと最適性の理論保証が必要なミッションクリティカルシステム :: 
     製造システム、運送 (時間=お金)

     人工衛星 (燃料使いきれば運用終了)

     間違った解は許されない
+ 思考過程を説明可能なシステム :: 
     レスキュー・宇宙船 (人間の安全がかかっている)
#+END_LARGER

# [[sjpg:martian]]

#+END_SPAN7
#+BEGIN_SPAN5

[[sjpg:gravity-m]]

#+END_SPAN5
#+END_ROW-FLUID
#+END_CONTAINER-FLUID




** AIと自動プランニング の位置づけ -- /理論/ と /実応用/ の中間    :noexport:

 緑は /理論/ 、オレンジは /実応用/ 、 AI はその橋渡し (どれともかぶらない部分もある)

 #+BEGIN_RESUME
 Automated Planning is a branch of Aritificial Intelligence. 

 It shares a lot of technology with Operations Research and Theoretical
 Computer Science, and is considered a bridge between pure theory and
 pure applications.
 #+END_RESUME

 [[png:planning-related-field]]

* 古典プランニング問題 (決定的,完全情報) -- Blocksworld

#+HTML: <embed src="img/plan.svg" type="image/svg+xml"  />

#+BEGIN_LARGER
非古典的なさまざまな拡張
#+BEGIN_ALIGNRIGHT
(並列アクション,POMDP,HTN... どのAIの教科書にものっている)
#+END_ALIGNRIGHT
#+END_LARGER

** アクション = 条件付き状態遷移

#+BEGIN_CENTER
#+BEGIN_XLARGE
アクション (move ?X ?Y)
#+END_XLARGE
#+END_CENTER

#+BEGIN_CENTER
*?X*, *?Y* : 変数。 値 *BLOCK-A*, *BLOCK-B* などを適用して使う

*条件* と *効果* で構成される
#+END_CENTER


#+BEGIN_CONTAINER-FLUID
#+BEGIN_ROW-FLUID
#+BEGIN_SPAN7
#+BEGIN_QUOTE
*条件* : 実行に必要な条件を表す命題

　(clear *?X*) : 積み木 *?X* の上が空

　(clear *?Y*) : 積み木 *?Y* の上に空

*効果* : 前後の状態の *差分* を表す命題

　(on *?X* *?Y*) を *追加* : *?Y* の上は *?X*

　(clear *?Y*) を *削除*
#+END_QUOTE
#+END_SPAN7
#+BEGIN_SPAN5
#+BEGIN_SRC lisp
(:action move
 :parameters (?X ?Y)
 :preconditions
   (and (clear ?X)   ; (1)
        (clear ?Y))  ; (2)

 :effect
   (and (on ?X ?Y)   ; (3)
        (not         ; (4)
         (clear ?Y))))
#+END_SRC
#+BEGIN_ALIGNRIGHT
#+BEGIN_LARGER
モデリング言語 *PDDL* で記述
#+END_LARGER
#+END_ALIGNRIGHT
#+END_SPAN5
#+END_ROW-FLUID
#+END_CONTAINER-FLUID

** *PDDL* : Planning Domain Description Language                   :noexport:

International Planning Competition で使われている入力形式

#+BEGIN_CONTAINER-FLUID
#+BEGIN_ROW-FLUID
#+BEGIN_SPAN2

#+END_SPAN2
#+BEGIN_SPAN8
#+BEGIN_SRC lisp
(:action move
 :parameters (?X ?Y)
 :preconditions
   (and (clear ?X)   ; (1)
        (clear ?Y))  ; (2)

 :effect
   (and (on ?X ?Y)   ; (3)
        (not         ; (4)
         (clear ?Y))))
#+END_SRC
#+END_SPAN8
#+BEGIN_SPAN2

#+END_SPAN2
#+END_ROW-FLUID
#+END_CONTAINER-FLUID

** プランニング = グラフ探索

*ノード* : 状態 = 命題の集合 ⇒ =(on A B)=, =(clear A)= など

*辺*     : アクション ⇒ =(move A B)= 等

[[png:graph]]

# #+BEGIN_CONTAINER-FLUID
# #+BEGIN_ROW-FLUID
# #+BEGIN_SPAN6
# # + ヒューリスティック探索 A*
# # + State-of-the-Art *1
# #+END_SPAN6
# #+BEGIN_SPAN6
# # #+attr_html: :width 50%
# #+END_SPAN6
# #+END_ROW-FLUID
# #+END_CONTAINER-FLUID

#+BEGIN_NOTE
*1 [Helmert, 2006] [Richter, 2010]
#+END_NOTE
  
** Q. いま */はやり/* のDeep Learningとの違いは?

 A. レイヤが違う

 #+BEGIN_CONTAINER-FLUID
 #+BEGIN_ROW-FLUID
 #+BEGIN_SPAN6
 *機械学習・Neural Networks* 
 
 for *認識・反射*
 + 入力 は *Subsymbolic* (連続値)
   
   画像、音声、非構造化テキスト: 
 + *感覚的知能*:
   
   　 */反応/, /直後/ の行動の決定*
   #+BEGIN_SMALLER
   *パブロフの犬* : 餌を認知→よだれ

   *自動運転* : 赤信号,人 → 止まる.

   *翻訳* : 文章 → 文章

   *囲碁局面の評価関数* : 局面 → 勝率
   #+END_SMALLER
   #+BEGIN_LARGER
   ☺ 効率よく 1-to-1 mapping
   
   ☹ 単純作業
   #+END_LARGER
 #+END_SPAN6
 #+BEGIN_SPAN6
 *推論・探索*

 for *プランニング・ゲーム・定理証明*
 + 入出力は *Symbolic*
   
   論理 オブジェクト ルール
 + *論理・推論による知能:*

   　 */未来に渡る/ 戦略の決定*
   
   　 (戦略 = 行動の *列や木*)
   #+BEGIN_SMALLER
   *レスキューロボ* : ゴール = 被災者生存

   *証明器* : ゴール = QED

   *コンパイラ* : 命令列の生成
   
   *囲碁,将棋* : ゴール = 勝利
   #+END_SMALLER
   #+BEGIN_LARGER
   ☺ 順序制約+複雑な作業
   #+END_LARGER
 #+END_SPAN6
 #+END_ROW-FLUID
 #+END_CONTAINER-FLUID

+ AlphaGo = Subsymbolic (DLNNによる評価関数) + Symbolic (MCTSによる探索)

** 既存の有名システム

AlphaGo = Subsymbolic (NNによる評価関数) + Symbolic (MCTSによる探索)
+ ただし *ドメイン依存* -- 囲碁に特化, "マス目"や"石"といった概念をハードコード
+ *膨大な棋譜が必要* --- 運用データがない環境(e.g.火星)には適用不能
+ */人って模範解答がないと行動できませんか?/* *真の自律機械は前例無しでも行動可能*

DQN = Subsymbolic (DLNN) + 強化学習 (DLNN)

様々な Atari Game につかえる汎用フレームワーク (Invader, Packman…) だが
+ RLのActing: 学習したpolicyに従ってgreedyに行動
+ Atariゲームは *脊髄反射で生き残ることが可能* → *複雑な論理思考はいらない!*
  
# 実際 *Sokoban など論理思考ゲームでは性能が悪い* ↔ 倉庫番ソルバ

* 記号的AIによる論理推論の重要性

[[png:lecun]]

#+BEGIN_ALIGNRIGHT
それと去年の松尾先生
#+END_ALIGNRIGHT

* IJCAI投稿内容                                                    :noexport:

#+BEGIN_XLARGE
#+BEGIN_CENTER
Classical Planning in

 Deep Latent Space:

From Unlabelled Images to PDDL (and back)
#+END_CENTER
#+END_XLARGE

** 高度に知的な機械を作るには → DeepLearning + 論理と推論         :noexport:

#+BEGIN_CENTER
#+BEGIN_CONTAINER-FLUID
#+BEGIN_ROW-FLUID
#+BEGIN_SPAN5
+ ディープラーニングのみ
  
  ↓
  
  虫程度の知能を持った
  
  *反射的な機械*
#+END_SPAN5
#+BEGIN_SPAN2
　

vs

　
#+END_SPAN2
#+BEGIN_SPAN5
+ */DL + 論理、推論、思考/*
  
  ↓
  
  */目標を達成するために/*
  
  */論理で戦略を練る機械/*

#+END_SPAN5
#+END_ROW-FLUID
#+END_CONTAINER-FLUID
#+END_CENTER

[[png:planning-deeplearning]]
* ゴール

#+BEGIN_XLARGE
#+BEGIN_CENTER
Deep Learning

＋

古典プランニング
#+END_CENTER
#+END_XLARGE

** 利点

#+BEGIN_XLARGE
*/認知/* はDLNNベース
#+END_XLARGE

--- 柔軟、ロバスト、DL技術の発展を利用できる

#+BEGIN_XLARGE
*/意思決定/* を古典プランニングで
#+END_XLARGE

--- *強化学習にない理論的性質* 

#+BEGIN_CENTER
*完全性* (解があれば必ず見つける), */解の最適性/* (必ず最適解を返す)
#+END_CENTER

--- *意思決定が学習に依存しない*

#+BEGIN_CENTER
*/教師なし/* (データがいらない), *説明可能* (記号処理による探索)
#+END_CENTER


# 今まではNNとの相性から強化学習が優勢だったが *もうその必要はない*

** 3x3 スライディング タイル パズル (8-Puzzle)

空きパネルとそれ以外を移動させることで絵を完成させるパズル

#+BEGIN_CENTER
*古くからあるAI問題*, 可能な曲面の数は 362880 個

4x4、5x5のパズルは */全探索では/ 探索空間が指数爆発→メモリ不足で解けない*

*/古典プランニングの理論保証付き下界関数を使えば/ 最適解を求められる*
#+END_CENTER

[[sjpg:puzzle]]

** ゴール: 棋譜・事前知識なし 画像のみで8パズルを解くAI

*DLNN + 古典プランニング*

*事前知識なし* : 「9マスある」「動くパネル」など人の与えた *ラベル・シンボルなし*

*棋譜なし* : AlphaGoは 棋譜から学習した評価関数で解く → *理論保証付き下界関数* で解く

[[sjpg:puzzle]]

** ゴール: 棋譜・事前知識なし、画像のみで */任意の問題/* を解くAI

#+BEGIN_XLARGE
*/事前知識なしで解ける/*

#+BEGIN_ALIGNRIGHT
*＝ /任意の問題を解ける/*
#+END_ALIGNRIGHT
#+END_XLARGE

#+BEGIN_CONTAINER-FLUID
#+BEGIN_ROW-FLUID
#+BEGIN_SPAN6
ハノイの塔

[[sjpg:hanoi]]
#+END_SPAN6
#+BEGIN_SPAN4
Lights-Out

[[sjpg:lightsout]]
#+END_SPAN4
#+END_ROW-FLUID
#+END_CONTAINER-FLUID

* -

#+BEGIN_XLARGE
#+BEGIN_CENTER
システム概要
#+END_CENTER
#+END_XLARGE

** 入力1: Training Inputs -- Image Pairs

実行可能なアクションの例を示す画像ペア

[[png:overview/1]]

** 入力1: Training Inputs -- Image Pairs

[[png:overview/2]]

** 入力2: Planning Inputs -- Initial Image & Goal Image

探すべきプランの *始点と終点* にある2つの状態 を示す画像

[[png:overview/input2]]

** 論文のゴール: 棋譜なし・事前知識なし 訓練画像のみ 完全自動で */任意の問題/* を解くAIシステムを作る

#+HTML: <embed src="img/overview/3.svg" type="image/svg+xml"  />

** 論文のゴール: 棋譜なし・事前知識なし 訓練画像のみ 完全自動で */任意の問題/* を解くAIシステムを作る

#+HTML: <embed src="img/overview/3-hanoi.svg" type="image/svg+xml"  />

* 実行例 (MNIST 8-puzzle)

[[png:results/mnist-plan]]

#+BEGIN_LARGER
最適解が知られている問題の画像版
#+BEGIN_XLARGE
#+BEGIN_ALIGNRIGHT
 → *31手の最適解を返却*
#+END_ALIGNRIGHT
#+END_XLARGE
#+END_LARGER

** 実際の問題の例 (マンドリル 8-puzzle)                            :noexport:

MNIST 8-puzzle は 「物体」のようなものが明確に分離されている

この実験 は このシステムがそのような特性に左右されないことを示す

[[png:results/mandrill-intro]]

** 写実的な画像 + 明確に分かれていないタイルでの実行例 (マンドリル 8-puzzle)

[[png:results/mandrill-plan]]

#+BEGIN_XLARGE
#+BEGIN_ALIGNRIGHT
 → *同様に最適解を返却*
#+END_ALIGNRIGHT
#+END_XLARGE

** 実行例 (ハノイの塔)

全く意味の異なる入力でも解けることを示す

[[png:results/hanoi3]]

[[png:results/hanoi4]]

#+BEGIN_ALIGNRIGHT
#+BEGIN_XLARGE
 → *同様に最適解を返却* (7手,15手)
#+END_XLARGE

他にも2種類の問題で実験
#+END_ALIGNRIGHT

** ノイズのある入力にも対応

# Denoising AE を使っているため入力ノイズに左右されずにプランを求められる

[[png:results/noise]]

#+BEGIN_XLARGE
#+BEGIN_ALIGNRIGHT
 → *同様に最適解を返却*
#+END_ALIGNRIGHT
#+END_XLARGE

# (ノイズのある入力 $r$ と、それにSAEを適用した $Decode(Encode(r))$ の比較)

* 動くのはわかった。どうやって作ったの？

基本アイディア: DLNN + Classical Planner

+ 1. ラベル無し画像データからなんとかして知識を取り出したい

  + *どんな知識をどうやって?* ← *自明でない*

+ 2. NNの出力は Subsymbolic: *実数値* ↔ Symbolic な *離散値・命題* がほしい

  + *Symbol Grounding* ← *自明でない*

+ 3. 機械が作った Symbol は *人間には理解不能* 

  + *意味不明の記号列をどうやって人の理解できる形式にするか？* ← *自明でない*

* Latent-Space Planner: */LatPlan/*

3つの課題を同時に解決する *アーキテクチャ*

 [[png:overview/planning1]]

#+BEGIN_ALIGNRIGHT
本プレゼンテーションでは、 LatPlan と その *1実装* LatPlanα を紹介
#+END_ALIGNRIGHT

* Step 1: State Autoencoder

*Symbolic/Subsymbolic の壁を超える* ために・・・

 [[png:overview/planning2]]

** AutoEncoder (おさらい)

#+BEGIN_CENTER
*教師なし学習*

入力空間 *S* を Latent Space *L* に *圧縮*

かつ *S* に *展開* して *元の画像に損失無く戻す。*
#+END_CENTER

#+BEGIN_CONTAINER-FLUID
#+BEGIN_ROW-FLUID
#+BEGIN_SPAN3

#+END_SPAN3
#+BEGIN_SPAN6
[[png:static/autoenc]]
#+END_SPAN6
#+BEGIN_SPAN3

#+END_SPAN3
#+END_ROW-FLUID
#+END_CONTAINER-FLUID

#+BEGIN_ALIGNRIGHT
→ *データ* $x$ をコンパクトな *Latent vector* $z$ に変換/逆変換するNNを学習

→ しかし、 */✘ Latent vector は 実数値 のよくわからん値/*
#+END_ALIGNRIGHT

** Deep Autoencoder                                                :noexport:

 いろいろな追加技術を使うことでDeepにできる → *より圧縮できる*

 Stacked AE, pretraining, CNN, dropout, Batch-Normalization, GPU...

 [[png:static/deep-ae]]

** Gumbel-Softmax Reparametrization (Jang, Gu, ICLR2017)

 *中間層がカテゴリカル分布(離散値)なVAEを作る手法*

VAE: 中間層が特定の分布を持つAEのこと。 下図: カテゴリ数8, 30変数 の GumbelSoftmax

#+BEGIN_CENTER
 #+BEGIN_HTML
 <svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="649px" height="206px" version="1.1" content="&lt;mxfile userAgent=&quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.71 Safari/537.36&quot; version=&quot;6.0.1.2&quot; editor=&quot;www.draw.io&quot; type=&quot;google&quot;&gt;&lt;diagram name=&quot;Page-1&quot;&gt;3ZhLc5swEMc/Dcd0kAQCX+O67SGd6TTTaXqU0fJoZcsjy69++oogDBjs0MZ2TONDpL9ey29Xi5BDxrPtR8UW6WfJQTjY5VuHvHcwxshF5l+u7AqF+rgQEpXxQkKV8Jj9Biu6Vl1lHJaNjlpKobNFU4zkfA6RbmhMKblpdoulaK66YAm0hMeIibb6PeM6LdTQdyv9E2RJWq6MXNsyY2VnKyxTxuWmJpGJQ8ZKSl2UZtsxiBxeyaUY9+FI694wBXPdZ0AQh1EYx4xP46kXRHBnZ1gzsbIPaw3Vu/LpN2mm4XHBory+MR52yH2qZ8LUkCnGmRBjKaR67k0AcR8Coy+1kr+g1jKiAWHUtCi5mnPgdrw1AJSG7dGnQntWJshAzkCrneliB5CAFENsfCHPL+qbylt7n6Q1T+HAisxGSLKfu4JoCpZjT6a4xRT71MFUmFXvebY2xSQvfoWHb6VsFqm1tHygUjmbroyR9y944ww08QFN7LktmmEHzPASLEmLpY/wcFiiW2LptVAAN3nOVqXSqUzknIlJpdb2qtuEA9tMP9XKP/Iu7/y8NjeGPtkRz5Wq7SdovbMJnq20NFK17oOUiwb63LzT4M3TyJWK4HT0aKYS0Kd2a9uBCgTT2bq5/mvc4eEIU4xG4PsesCDqCO1z+ufKpBHugZq8FeorRf6VmfdBfiQ9XR45HXbi9kf4zRJ3i2Uw7AOFd0ssw//9JXgseupponu3Ht8MwYEDL+KZ0cDehyeBBqd3BB31B2pn+SIzY0D/KYqYsKMO3LK36N88hc7+1cgZhHHU9dVIoxCm8SW+GukINQm67bSEaEde2otnDX901nAfRGaiPTYSutYJ5uiRdthRfldeot1IlPfI8i9Abcb8AeLYz3+diJ//Xgm1hIg6IHpdEL1LQCxvEwcK0Q4I3IP8+8ZQX/9SuwGoJGxud+STFtSQtpli3/trpqZa3VwX54rq/p9M/gA=&lt;/diagram&gt;&lt;/mxfile&gt;"><defs/><g transform="translate(0.5,0.5)"><rect x="288" y="0.75" width="75" height="202.5" rx="11.25" ry="11.25" fill="#e1d5e7" stroke="#9673a6" pointer-events="none"/><path d="M 243 72 L 273 102 L 243 132 L 213 102 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(231.5,91.5)scale(0.75)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; word-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">256<div>ReLU</div></div></div></foreignObject><text x="15" y="19" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">[Not supported by viewer]</text></switch></g><path d="M 168 72 L 198 102 L 168 132 L 138 102 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(156.5,91.5)scale(0.75)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; word-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">512<div>ReLU</div></div></div></foreignObject><text x="15" y="19" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">[Not supported by viewer]</text></switch></g><path d="M 198 102 L 208.22 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 212.16 102 L 206.91 104.63 L 208.22 102 L 206.91 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 120.75 102 L 135.75 102 L 123 102 L 133.22 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 137.16 102 L 131.91 104.63 L 133.22 102 L 131.91 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 273 102 L 288 102 L 273 102 L 283.22 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 287.16 102 L 281.91 104.63 L 283.22 102 L 281.91 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 482.25 72 L 512.25 102 L 482.25 132 L 452.25 102 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(470.5,91.5)scale(0.75)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; word-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">512<div>ReLU</div></div></div></foreignObject><text x="15" y="19" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">[Not supported by viewer]</text></switch></g><path d="M 407.25 72 L 437.25 102 L 407.25 132 L 377.25 102 Z" fill="#ffffff" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><g transform="translate(395.5,91.5)scale(0.75)"><switch><foreignObject style="overflow:visible;" pointer-events="all" width="30" height="26" requiredFeatures="http://www.w3.org/TR/SVG11/feature#Extensibility"><div xmlns="http://www.w3.org/1999/xhtml" style="display: inline-block; font-size: 12px; font-family: Helvetica; color: rgb(0, 0, 0); line-height: 1.2; vertical-align: top; width: 32px; white-space: nowrap; word-wrap: normal; text-align: center;"><div xmlns="http://www.w3.org/1999/xhtml" style="display:inline-block;text-align:inherit;text-decoration:inherit;">256<div>ReLU</div></div></div></foreignObject><text x="15" y="19" fill="#000000" text-anchor="middle" font-size="12px" font-family="Helvetica">[Not supported by viewer]</text></switch></g><path d="M 437.25 102 L 447.47 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 451.41 102 L 446.16 104.63 L 447.47 102 L 446.16 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 360 102 L 375 102 L 362.25 102 L 372.47 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 376.41 102 L 371.16 104.63 L 372.47 102 L 371.16 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><rect x="526.5" y="42" width="120" height="120" rx="18" ry="18" fill="#dae8fc" stroke="#6c8ebf" pointer-events="none"/><path d="M 512.25 102 L 521.72 102" fill="none" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><path d="M 525.66 102 L 520.41 104.63 L 521.72 102 L 520.41 99.38 Z" fill="#000000" stroke="#000000" stroke-miterlimit="10" pointer-events="none"/><rect x="0.75" y="42" width="120" height="120" rx="18" ry="18" fill="#dae8fc" stroke="#6c8ebf" pointer-events="none"/>
 <image xlink:href="img/static/x0.gif" x="8.25" y="49.5" width="105" height="105" fill="#f5f5f5" stroke="#666666" pointer-events="none"/>
 <image xlink:href="img/static/x1.gif" x="534" y="49.5" width="105" height="105" fill="#f5f5f5" stroke="#666666" pointer-events="none"/>
 <image xlink:href="img/static/y.gif" x="293.25" y="6.75" width="64.5" height="190.5" fill="#f5f5f5" stroke="#666666" pointer-events="none"/></g></svg>
 #+END_HTML
#+END_CENTER

#+BEGIN_ALIGNRIGHT
#+BEGIN_LARGER
鍵となるアイディア: *この離散表現は記号的ソルバで使用可能*

特に *カテゴリ数2 → N個の命題(true/false)に直接マップ可能*
#+END_LARGER
#+END_ALIGNRIGHT

** Step 1: State Autoencoder                                       :noexport:

 [[png:sae/state-ae]]

** Gumbel-Softmax: Gumbel-Max の微分可能な近似                     :noexport:

Gumbel-Max: カテゴリごとの確率 ($x$) から one-hot vector ($z$) をサンプルする手法

+ 例: $x=[0.1, 0.1, 0.8] \rightarrow z = [0, 0, 1] \text{or} [1,0,0] \text{or} [0,1,0]$ (確率にそって)

+ $z = \text{ GumbelMax}(x) = [ i == \arg \max_j (\text{ Gumbel}(0,1)+\log x_j) \; ? \; 1 : 0 ]$

+ 微分可能でない → BP法が使えない → max を 微分可能なsoftmax で近似

+ $z = \text{ GumbelSoftmax}_\tau (x) = \text{ Softmax}( [\text{ Gumbel}(0,1)+\log x_j]/\tau )$

+ 温度 $\tau$ を0に近づけるとGumbelMaxに収束: $z$ もone-hotに収束

  \[
  \text{ GumbelSoftmax}_\tau (x) \rightarrow \text{ GumbelMax}(x) \quad (\tau\rightarrow 0)
  \]

#+BEGIN_NOTE
Maddison et. al., 2014
#+END_NOTE

** Step 1: State Autoencoder

[[png:train-state-ae]]

SAEを学習させることにより以下の関数を得る:

+ $b = Encode(r)$ : *生データ $r$ を 命題列 $b$ に変換する関数*

+ $\tilde{r} = Decode(b)$ : *命題列 $b$ を 生データ $\tilde{r}$ に変換する関数*

* Step 2: Domain Acquisition (ドメイン獲得)

bitvector から PDDL モデルを生成する

 [[png:overview/planning3]]

** LatPlan の実装 LatPlan α での アクション集合の生成

個別アクション遷移をPDDLアクション表現にマップ

#+BEGIN_SRC lisp
 0011 → 0101

　　　↓

(:action ...
 :precondition (and (b0-false) (b1-false) (b2-true) (b3-true)) ; 遷移前の状態
 :effect       (and (not (b1-false)) (b1-true)    ; false命題を取り除き、true命題を追加
                    (not (b2-true))  (b2-false)))
#+END_SRC

ポイント:

#+BEGIN_CENTER
 $i$ ビット目が 1 → 命題 ($b_i$-true)

 $i$ ビット目が 0 → 命題 ($b_i$-false)
#+END_CENTER

* Step 3: PDDL モデルを解く

 [[png:overview/planning4]]

* Step 4: 記号的プラン(人には理解不能)を 人の理解できる画像に戻す

 [[png:overview/planning5]]

* わざわざプランニングソルバを使う理由は?

なぜ、ただの幅優先やDijkstra探索ではだめなの?

→ 大規模な問題(5x5パズル等)で *指数爆発* し、非実用的

→ *ドメイン非依存下界関数* (*PDB*) による枝刈り が、この未知のドメインでも有効

#+BEGIN_SMALLER
|------------------------+----------+----------+--------|
| /                      |        < |        > | <>     |
|                        |          |      <r> |        |
| 探索ノード数           | Dijkstra |   A*+PDB | 高速化 |
|------------------------+----------+----------+--------|
| MNIST 8-puzzle         |   193924 | *109096* | x2     |
|------------------------+----------+----------+--------|
| MNIST 8-puzzle         |   201156 | *111642* | x2     |
|------------------------+----------+----------+--------|
| MNIST 8-puzzle         |   186767 |  *84561* | x2     |
|------------------------+----------+----------+--------|
| MNIST 8-puzzle         |   183336 |  *82518* | x2     |
|------------------------+----------+----------+--------|
| MNIST 8-puzzle         |   169907 |  *52084* | x3     |
|------------------------+----------+----------+--------|
| MNIST 8-puzzle         |   130863 |  *26967* | x5     |
|------------------------+----------+----------+--------|
| Hanoi (4 peg)          |       55 |     *17* | x3     |
|------------------------+----------+----------+--------|
| LightsOut (4x4)        |      952 |     *27* | x30    |
|------------------------+----------+----------+--------|
| Spiral LightsOut (3x3) |      522 |    *214* | x2.5   |
|------------------------+----------+----------+--------|
| Mandrill 8-puzzle      |   335378 |  *88851* | x4     |
|------------------------+----------+----------+--------|
#+END_SMALLER

#+BEGIN_LARGER
#+BEGIN_ALIGNRIGHT
→ */プランナを使えば既存の様々な下界関数を利用できる!/*
#+END_ALIGNRIGHT
#+END_LARGER

# #+BEGIN_LARGER
# PDB: Pattern DataBase ヒューリスティクス
# 
# 注: *プランニングでは理論保証付き下界関数のことをヒューリスティック関数と呼ぶ*
# #+END_LARGER

* Conclusion

+ 入力: ラベル無しの 状態遷移の画像・初期画像・ゴール画像
+ 出力: ゴールを達成するためのプランを表す画像列
+ State AutoEncoder(SAE): Gumbel-Softmaxを用いたVAE
+ */成果/* : *SAEによって生データから命題を生成 → 古典プランニング問題として解ける* ことを実証
+ */限りなく単純に作った/* プロトタイプ 

  → 記号/非記号AI分野の様々な技術を取り入れることで */より発展/*

JSAI予稿論文は 短縮版です。

#+BEGIN_LARGER
Arxiv 1705.00154 : *Classical Planning in Deep Latent Space: Bridging the Subsymbolic-Symbolic Boundary.*

KEPS17採択版: *Classical Planning in Deep Latent Space: From Unlabeled Images to PDDL (and back).*  /Knowledge Engineering for Planning and Scheduling (KEPS) Workshop in ICAPS2017/
#+END_LARGER


* LatPlan の実装 LatPlan α でのSAE

Keras, Adam optimizer (learning rate:0.001)

  1764(42x42)

  [→FC(4000,ReLu)→Batchnorm→Dropout(0.4)] × 2

  →FC(49,GumbelSoftmax) (variational loss)

  [→FC(4000,ReLu)→Batchnorm→Dropout(0.4)] × 2

  →1764(42x42) (loss: Binary crossentropy)

　

+ なぜ全結合?? ::
             論文の主題は *SAEで命題を作る方針がそもそもうまく行くかどうか*
             
             *→余計な要素を省いて限りなくシンプルに*
             
+ 8-パズルでの訓練 ::
               可能な全状態 (362880) 中 *12000 枚* で訓練 → 汎化能力あり

* Gumbel-Softmax

[[png:sae/gumbel]]

$N\times M$ 行列を出力, $N$: 変数の数 $M$: カテゴリの数

* LatPlan の実装 LatPlan α での アクション集合の生成

_全遷移の画像ペア $R$ を生成_ → $Encode(R)$ → PDDL

なぜ? → *本来は汎化されたルールを得られると良い*

: 未汎化の遷移   0011 → 0101  (遷移前の全ビットを指定)
: 汎化された遷移 *01* → *10*  (一部のビットのみを指定)

+ LatPlanα: 一般化を行わない ::

     論文の主題は *SAEで命題を作る方針がそもそもうまく行くかどうか*
     
     *→余計な要素を省いて限りなくシンプルに*
     
     *汎化ルール → 他の Domain Acquisition 学習機^1 をそのまま使えば良い (Future work)*

#+BEGIN_NOTE
[Konidaris et.al. 14; Cresswell et al 13]
#+END_NOTE

* 他の実行例 (Lights Out)

8-puzzle も hanoi も 「物体」のようなものが「消えない」という性質がある。

この実験 は このシステムがそのような特性に左右されないことを示す

[[png:results/lights-out]]

#+BEGIN_XLARGE
#+BEGIN_ALIGNRIGHT
 → *同様に最適解を返却*
#+END_ALIGNRIGHT
#+END_XLARGE

* 他の実行例 (Skewed Lights Out)

8-puzzle, hanoi, LightsOut は 「物体」のようなものが格子状に並んでいる

この実験 は このシステムがそのような特性に左右されないことを示す

[[png:results/lights-out-skewed]]

#+BEGIN_XLARGE
#+BEGIN_ALIGNRIGHT
 → *同様に最適解を返却*
#+END_ALIGNRIGHT
#+END_XLARGE

* 正しくない解が出力される可能性はないの？

*ニューラルネットの誤差が大きい場合のみ発生* (収束保証は $t\rightarrow \infty$ のみ, not 実時間)

 → でたらめなシンボル/グラフが生成

 → *でたらめな離散グラフ上の正しいプラン* が生成 / *グラフが非連結* で解なし

#+BEGIN_ALIGNRIGHT
 (アルゴリズムの完全性、健全性、最適性により保証)
#+END_ALIGNRIGHT

 → でたらめな画像プラン / 解が存在しない

#+BEGIN_CENTER
#+BEGIN_LARGER
LatPlan に */認識の間違いはある/* が */判断の間違いはない!/*
#+END_LARGER
#+END_CENTER

#+BEGIN_ALIGNRIGHT
 (完全性,最適性) →強化学習に対する強み
#+END_ALIGNRIGHT

** 強化学習

*意思決定も学習に依存する*

→ */個別の学習結果に理論保証はない。/*

→ */Policy関数が正しく学習されなかった局面では失敗する。/*

#+BEGIN_QUOTE
セドルはそれから、左手で首の後ろに触れたまま次の手を打った。... 
コンピューターは驚きを隠せなかった。もちろん目をパチクリさせたわけではないが、次の1手はひどいものだった。
[白78手について]
#+END_QUOTE
#+BEGIN_ALIGNRIGHT
Cade Metz. "Two Moves, that Redifined the Future." /Wired/, 2016
#+END_ALIGNRIGHT

#+BEGIN_CENTER
#+BEGIN_LARGER
RLは *判断に間違いがあり得る。*
#+END_LARGER
#+END_CENTER

* Future Work (SAE)

SAEは命題の検出が可能 (状態s = p∧q∧r...)

→ 一階述語への一般化 (述語 p(a,b) )

→ オブジェクトの検出 (引数 a,b) が必要

→ 物体認識(R-CNN) などを内部で用いる より複雑なSAEの使用で対処可能

* Future Work (問題ドメイン)

LatPlan は あくまで *アーキテクチャ*

*SAE の実装を変えれば(原理的には)画像以外の任意の入力データに対応可能なはず*

+ テキスト用のAE [Li et.al. 2015]、 音声用のAE [Deng, Li, et al. 2010]
+ 改造してSAEにすれば・・・
  + *Here's an Apple, Here's a pen → oh, ApplePen!*
+ SAEを学習してプランナで解く → *数千ステップの高速な言語レベル推論が可能に*

#+BEGIN_NOTE
 "A hierarchical neural autoencoder for paragraphs and documents." (2015)

 "Binary coding of speech spectrograms using a deep auto-encoder." (2010)
#+END_NOTE

* 苦言                                                             :noexport:

日本には記号的AIの研究者が居なさすぎて完全に砂漠状態 (OR除く)

意思決定と推論に重要な *抽象(abstraction)* や *緩和(relaxation)* といった概念

特に、対話技術とかを古典AIの概念と推論を用いずにやっているかぎり、人工無能以上には成り得ない

# JSAI は *技術* でなくて *目的* によってOSを分けるべき
# 
# + *ディープラーニング* OSと *論理* ではなく 

* AIMA 3rd Ed.                                                     :noexport:

1. Introduction
2. Intelligent Agents
3. Solving Problems by Searching
4. Beyond Classical Search
5. Adversarial Search
6. Constraint Satisfaction Problems
7. Logical Agents
8. First-Order Logic
9. Inference in First-Order Logic
10. Classical Planning
11. Planning and Acting in the Real World
12. Knowledge Representation
13. Quantifying Uncertainty
15. Probabilistic Reasoning over Time
16. Making Simple Decisions
17. Making Complex Decisions
18. Learning from Examples
19. Knowledge in Learning
20. Learning Probabilistic Models
21. Reinforcement Learning
22. Natural Language Processing
23. Natural Language for Communication
24. Perception
25. Robotics
26. Philosophical Foundations
27. AI: The Present and Future

* 記号・記号処理とは

*記号の特徴と強み* : なぜ記号は強力な抽象化の道具なのか？

+ 理解する必要がない ::
     ルールを機械的に適用することだけによって論理推論を行える
     
     シンボル $X$ の意味がリンゴだろうと車だろうと ルールが正しければ推論できる
     
     + ドメイン非依存ソルバの顕著な例: *mystery* ドメインと *nomystery* ドメイン

       *シンボル名だけデタラメ* にした荷物配送ベンチマーク (truck → shark)

       */(名前を見て特殊アルゴリズムを使う不正を禁じるため)/*
  
+ 組み合わせが可能 :: 
     Latent vector は 複数の命題の連言 (and) → modus ponens が適用可能になる
     
     探索の下界関数はこれらを適用してゴールへの近さを見積もる

+ ノイズを含む画像ピクセルはそのままではシンボルになれない ::

     ノイズの有無で画像は全く異なるデータになる → 何か *共通の特徴* の抽出が必要
     
     
* Arxiv版を上げた際のTwitterでの議論

 [[png:twitter]]

#+BEGIN_CENTER
#+BEGIN_XLARGE
*/AlphaGo チーム全員:/*

*/「古典プランニング超大事!」/*
#+END_XLARGE
#+END_CENTER

* 日本のプランニング研究者: */DL研究者よりさらに少ない/*

[[png:planning-researchers]]

* 評価

GTX1070, PhenomII X6 (3.4GHz OC), 16GB Mem

+ 学習: 30分程度
+ 求解: 3秒程度

** State AutoEncoder

1: Train入力 2: 生Latent 3: 生Autoencoding 4: 切り捨てLatent 5: 切り捨てLatentのAutoencoding

[[spng:experiment/autoencoding_train]]

** State AutoEncoder

1: Test入力 2: 生Latent 3: 生Autoencoding 4: 切り捨てLatent 5: 切り捨てLatentのAutoencoding

Test 入力: 訓練画像に含まれていない画像 (注!)

[[spng:experiment/autoencoding_test]]

#+BEGIN_ALIGNRIGHT
きちんと学習できている
#+END_ALIGNRIGHT

** State AutoEncoder

入力2: 初期画像とゴール画像

[[spng:experiment/init_goal]]

** PDDL Domain Definition

$N=25$ の例

#+BEGIN_SRC lisp
(define (domain latent)
 (:requirements :strips :negative-preconditions)
 (:predicates (z0) (z1) (z2) (z3) (z4) (z5) (z6) (z7) (z8) (z9) (z10)
  (z11) (z12) (z13) (z14) (z15) (z16) (z17) (z18) (z19) (z20) (z21)
  (z22) (z23) (z24))
 (:action a10000010010110111100011111000010001011111110011111
  :parameters () :precondition
  (and (z0) (not (z1)) (not (z2)) (not (z3)) (not (z4)) (not (z5))
       (z6) (not (z7)) (not (z8)) (z9) (not (z10)) (z11) (z12)
       (not (z13)) (z14) (z15) (z16) (z17) (not (z18)) (not (z19))
       (not (z20)) (z21) (z22) (z23) (z24))
  :effect (and (z5) (not (z6)) (z13) (z20)))
 (:action a10000010010110111100011110000001001011011110001110
  ...
#+END_SRC

** 先ほどの結果

#+BEGIN_CONTAINER-FLUID
#+BEGIN_ROW-FLUID
#+BEGIN_SPAN6

[[png:results/mnist-plan]]

[[png:results/mandrill-plan]]

#+END_SPAN6
#+BEGIN_SPAN6

[[png:results/hanoi3]]

[[png:results/hanoi4]]

[[png:results/lights-out]]

[[png:results/lights-out-skewed]]
#+END_SPAN6
#+END_ROW-FLUID
#+END_CONTAINER-FLUID

** Fast Downward Log Trace (Search Statistics)                     :noexport:

#+BEGIN_SRC
reading input... [t=5.479e-05 (sec)]
...
Building successor generator...done! [t=31.7737 (sec)]
done initalizing global data [t=31.7738 (sec)]
Conducting best first search with reopening closed nodes, (real) bound = 2147483647
Initializing landmark cut heuristic...
f = 4 [1 evaluated, 0 expanded, t=36.1569 (sec), 1054016 KB]
...
f = 12 [339 evaluated, 183 expanded, t=843.001 (sec), 1054016 KB]
f = 13 [553 evaluated, 314 expanded, t=1357.62 (sec), 1054016 KB]
f = 14 [942 evaluated, 529 expanded, t=2288.7 (sec), 1054016 KB]
Solution found!
Actual search time: 2688.73 (sec) [t=2724.89 (sec)]
a11010000010010000101001111101100010001000010100111 (1)
...
a10011100111110010010011011001111010111011001001111 (1)
a10011110101110110010011111001011001111011001001111 (1)
Plan length: 14 step(s).
Expanded 631 state(s).
Evaluated 1140 state(s).
Generated 1924 state(s).
Dead ends: 24 state(s).
Search time: 2693.06 (sec)
Total time: 2724.89 (sec)
#+END_SRC

